{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "## Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"SpotifyFeatures.csv\")\n",
    "\n",
    "num_samples = len(df.axes[0])\n",
    "num_features = len(df.axes[1])\n",
    "print(\"Number of samples =  \" + str(num_samples))\n",
    "print(\"Number of features = \" + str(num_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df.copy()\n",
    "df_sub = df_sub[(df[\"genre\"] == \"Pop\") | (df[\"genre\"] == \"Classical\")]\n",
    "df_sub[\"isPop\"] = df[\"genre\"].apply(lambda x: 1 if x == \"Pop\" else 0)\n",
    "\n",
    "num_songs_Pop = (df_sub[\"isPop\"] == 1).sum()\n",
    "num_songs_Classical = (df_sub[\"isPop\"] == 0).sum(0)\n",
    "\n",
    "print(\"Number of songs: Pop =  \" + str(num_songs_Pop))\n",
    "print(\"Number of songs: Classical = \" + str(num_songs_Classical))\n",
    "\n",
    "# subset: two features, namely ’liveness’ and ’loudness’\n",
    "df_sub = df_sub.loc[:, ['genre', 'artist_name', 'track_name', 'track_id', 'liveness', 'loudness', 'isPop']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make 2 numpy arrays\n",
    "df_sub_1 = df_sub.loc[:, ['liveness', 'loudness']].to_numpy()\n",
    "df_sub_2 = df_sub.loc[:, ['isPop']].to_numpy()\n",
    "\n",
    "# split into training and test data\n",
    "PERCENTAGE_TRAINING = 0.8\n",
    "\n",
    "# second array\n",
    "df_sub_2 = np.insert(df_sub_2, 1, -99, axis=1)\n",
    "\n",
    "maxPop = int(PERCENTAGE_TRAINING * num_songs_Pop)\n",
    "maxClassical = int(PERCENTAGE_TRAINING* num_songs_Classical)\n",
    "countPop = 0\n",
    "countClassical = 0\n",
    "\n",
    "## split second array into training and test data (first 80% go into training, rest into test)\n",
    "for row in df_sub_2:\n",
    "    if row[0] == 1 and countPop <= maxPop:\n",
    "        row[1] = 1\n",
    "        countPop += 1\n",
    "    elif row[0] == 0 and countClassical <= maxClassical:\n",
    "        row[1] = 1\n",
    "        countClassical += 1\n",
    "    else:\n",
    "        row[1] = 0 \n",
    "\n",
    "# based on classification in either trainig or test, split df_sub_2\n",
    "train_sub_2 = df_sub_2[df_sub_2[:, 1] == 1][:,0]\n",
    "test_sub_2  = df_sub_2[df_sub_2[:, 1] == 0][:,0]\n",
    "\n",
    "# split the first array in the same way as before (i.e. based on trainig/test column (=df_sub_2[i, 1] == 1))\n",
    "train_sub_1 = []\n",
    "test_sub_1 = []\n",
    "\n",
    "for i in range(0, len(df_sub_1)):\n",
    "    if df_sub_2[i, 1] == 1:\n",
    "        train_sub_1.append(df_sub_1[i, :]) \n",
    "    else:\n",
    "        test_sub_1.append(df_sub_1[i, :])\n",
    "\n",
    "# turn into numpy array\n",
    "train_sub_1 = np.array(train_sub_1)\n",
    "test_sub_1 = np.array(test_sub_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotFig():\n",
    "    # set colors for groups\n",
    "    class_colors = {1: 'red', 0: 'blue'}\n",
    "\n",
    "    # create plot with two axes\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for label, color in reversed(class_colors.items()):\n",
    "        subset = df_sub[df_sub['isPop'] == label]\n",
    "        plt.scatter(subset['liveness'], subset['loudness'], label=label, color=color, s=10)\n",
    "\n",
    "    # label plot\n",
    "    legend = plt.legend()\n",
    "    legend.get_texts()[0].set_text('Classical') \n",
    "    legend.get_texts()[1].set_text('Pop')  \n",
    "    plt.title('Liveness vs. Loudness')\n",
    "    plt.xlabel('Liveness')\n",
    "    plt.ylabel('Loudness')\n",
    "\n",
    "    # Save the plot to a file\n",
    "    plt.savefig('plots/1d.png')\n",
    "    return plt\n",
    "plotFig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle two data frames in the same way to keep the features and classification on the same row in both dataframes\n",
    "def shuffle_DFs(A, B):\n",
    "    perm = np.random.permutation(len(A))\n",
    "    return A[perm], B[perm]\n",
    "\n",
    "# source: https://stackoverflow.com/a/4602224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = 2\n",
    "NUM_EPOCHS = 1000\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "# logisic function\n",
    "def sigmoid(x):\n",
    "    return 1/ (1 + (math.exp(-x)))\n",
    "\n",
    "# predict value based on intercept and slope coefficients\n",
    "def predict(sample, intercept, slope):\n",
    "    yhat = intercept\n",
    "    for i in range(0, len(sample)):\n",
    "        yhat += slope[i] * sample[i]\n",
    "    if (sigmoid(yhat) >= 0.5):  # threshold is 0.5\n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "\n",
    "# calculate error value\n",
    "def error(df, df_features, intercept, weights):\n",
    "    error = 0\n",
    "    for i in range(len(df)):\n",
    "        error += math.pow((df[i] - predict(df_features[i], intercept, weights)), 2)\n",
    "    return error\n",
    "\n",
    "# use predict() on dataframe \n",
    "def predictDF(trainDF, trainDF_result, intercept, slope):\n",
    "    result = []\n",
    "    for i in range(0, len(trainDF)):\n",
    "        yhat = predict(trainDF[i, :], intercept, slope)\n",
    "        result.append(yhat)\n",
    "    return result\n",
    "    \n",
    "\n",
    "def fit(trainDF, trainDF_result):\n",
    "    errorList = []\n",
    "    NUM_SAMPLES = len(trainDF)\n",
    "    # initialize weights to random number\n",
    "    weights = np.random.rand(NUM_FEATURES) * 0.01\n",
    "    intercept = 0\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        for i in range(NUM_SAMPLES):\n",
    "            # compute linear combination of inputs and weights\n",
    "            linear_output = np.dot(trainDF[i], weights) + intercept\n",
    "            # compute sigmoid\n",
    "            y_predicted = sigmoid(linear_output)\n",
    "            # compute gradient\n",
    "            gradient = (y_predicted - trainDF_result[i]) * trainDF[i]\n",
    "            interceptDelta = y_predicted - trainDF_result[i]\n",
    "            # update weights\n",
    "            weights -= LEARNING_RATE * gradient\n",
    "            intercept -= LEARNING_RATE * interceptDelta\n",
    "\n",
    "        # store error value for plot    \n",
    "        errorList.append(error(train_sub_2, train_sub_1, intercept, weights))\n",
    "\n",
    "    return weights, intercept, errorList\n",
    "\n",
    "# generate shuffeled training data\n",
    "train_sub_1_shuffle, train_sub_2_shuffle = shuffle_DFs(train_sub_1, train_sub_2)\n",
    "\n",
    "# get coefficients and errors\n",
    "weights, intercept, errorList = fit(train_sub_1_shuffle, train_sub_2_shuffle)\n",
    "\n",
    "# get predicted yhats\n",
    "predicts_train = predictDF(train_sub_1_shuffle, train_sub_2_shuffle, intercept, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot\n",
    "plt.figure(figsize=(10, 6)) \n",
    "plt.plot(p.linspace(1, NUM_EPOCHS, NUM_EPOCHS), errorList, label='error', color='blue')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Error as a function of epoch with learning rate = '+ str(LEARNING_RATE))\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "\n",
    "# Display the plot\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the plot to a file\n",
    "plt.savefig('plots/2a_01.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate arrucacy based on ys and yhats\n",
    "def accuracy(df, predictDF):\n",
    "    TP_TN = 0 # since distinction of TP and TN, and FP and FN does not matter for accuracy value, so not distinguish\n",
    "\n",
    "    for i in range(0, len(df)):\n",
    "        if (df[i] == 1 and predictDF[i] == 1) or (df[i] == 0 and predictDF[i] == 0):\n",
    "            TP_TN += 1\n",
    "    return TP_TN/len(df)\n",
    "\n",
    "print(\"Training accuracy: \" + str(accuracy(train_sub_2_shuffle, predicts_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle test data sets in the same way to keep rows consistent\n",
    "test_sub_1_shuffle, test_sub_2_shuffle = shuffle_DFs(test_sub_1, test_sub_2)\n",
    "\n",
    "# predict values for test data\n",
    "predicts_test = predictDF(test_sub_1_shuffle, test_sub_2_shuffle,intercept, weights )\n",
    "\n",
    "print(accuracy(test_sub_2_shuffle, predicts_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotFig()\n",
    "\n",
    "# Create a grid to plot\n",
    "x_values = np.linspace(test_sub_1_shuffle[:, 0].min(), test_sub_1_shuffle[:, 0].max(), 100)\n",
    "y_values = (-intercept - weights[0] * x_values) / weights[1]\n",
    "\n",
    "# Plot the linear line separating\n",
    "plt.plot(x_values, y_values, color='black', linestyle='--', label='Decision Boundary')\n",
    "\n",
    "# Save the plot to a file\n",
    "plt.savefig('plots/2c.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate confusion matrix, here, distinction between types of (mis-) classification matters\n",
    "def confusion_matrix(df, predictDF):\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for i in range(0, len(df)):\n",
    "        if (df[i] == 1 and predictDF[i] == 1):\n",
    "            TP += 1\n",
    "        elif (df[i] == 0 and predictDF[i] == 0):\n",
    "            TN += 1\n",
    "        elif (df[i] == 1 and predictDF[i] == 0):\n",
    "            FN += 1\n",
    "        else:\n",
    "            FP += 1\n",
    "    return [[TP, FN], \n",
    "            [FP, TN]]\n",
    "\n",
    "conf_matr = confusion_matrix(test_sub_2_shuffle, predicts_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataframe that contains column whether Pop was predicted, yet sample is not Pop\n",
    "df_suggest = np.column_stack((test_sub_1_shuffle, test_sub_2_shuffle, predicts_test))\n",
    "df_suggest = pd.DataFrame(df_suggest, columns =  [\"liveness\", \"loudness\", \"isPop\", \"isPop_predicted\"])\n",
    "\n",
    "condition1 = df_suggest['isPop'] == 0\n",
    "condition2 = df_suggest['isPop_predicted'] == 1\n",
    "df_suggest_sub = df_suggest[condition1 & condition2]\n",
    "\n",
    "merged_df = pd.merge(df_suggest_sub, df_sub, on = ('liveness', 'loudness', 'isPop'), how = 'inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data with third class: Classical songs misclassified as Pop\n",
    "\n",
    "df_plot = df_sub.copy()\n",
    "df_plot.loc[df_plot['track_id'].isin(merged_df['track_id']), 'isPop'] = 2\n",
    "\n",
    "class_colors = {2: 'black', 1: 'red', 0: 'blue'}\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "for label, color in reversed(class_colors.items()):\n",
    "    subset = df_plot[df_plot['isPop'] == label]\n",
    "    plt.scatter(subset['liveness'], subset['loudness'], label=label, color=color, s=10, alpha = 0.8)\n",
    "\n",
    "# label plot\n",
    "legend = plt.legend()\n",
    "legend.get_texts()[0].set_text('Classical') \n",
    "legend.get_texts()[1].set_text('Pop') \n",
    "legend.get_texts()[2].set_text('Classical songs misclassified for Pop')  \n",
    "plt.title('Liveness vs. Loudness')\n",
    "plt.xlabel('Liveness')\n",
    "plt.ylabel('Loudness')\n",
    "\n",
    "# Save the plot to a file\n",
    "plt.savefig('plots/3c.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
